# æµ‹è¯•ç»“æœä¸€è‡´æ€§åˆ†ææŠ¥å‘Š

## ğŸ” é—®é¢˜æè¿°

åœ¨ç›¸åŒæµ‹è¯•ç¯å¢ƒå’Œæµ‹è¯•æ¡ä»¶ä¸‹ï¼Œå¤šæ¬¡æµ‹è¯•å‡ºç°è¾ƒå¤§å·®å¼‚ï¼Œç‰¹åˆ«æ˜¯è½¬å‘æ¬¡æ•°å­˜åœ¨æ˜æ˜¾ä¸ä¸€è‡´ï¼Œå¯¼è‡´é—²é€›å’Œè¡Œèµ°è¯†åˆ«ç»“æœä¸ç¨³å®šã€‚

## ğŸ“Š è§‚å¯Ÿåˆ°çš„ç°è±¡

ä»æä¾›çš„æ•°æ®å¯ä»¥çœ‹åˆ°ï¼š
- **IMEIç›¸åŒ**ï¼šæ‰€æœ‰æµ‹è¯•éƒ½æ˜¯åŒä¸€è®¾å¤‡
- **æ—¶é—´é—´éš”**ï¼šæµ‹è¯•é—´éš”è¾ƒçŸ­ï¼ˆ16:54-16:56ï¼‰
- **çŠ¶æ€å€¼å·®å¼‚**ï¼šè½¬å‘æ¬¡æ•°åœ¨ç›¸åŒæ¡ä»¶ä¸‹å‡ºç°è¾ƒå¤§æ³¢åŠ¨
- **å½±å“èŒƒå›´**ï¼šç›´æ¥å½±å“è¡Œä¸ºåˆ†ç±»çš„å‡†ç¡®æ€§

## ğŸ” å¯èƒ½çš„åŸå› åˆ†æ

### 1. æ•°æ®é‡‡é›†å±‚é¢çš„é—®é¢˜

#### A. ä¼ æ„Ÿå™¨æ•°æ®è´¨é‡
- **é™€èºä»ªæ¼‚ç§»**ï¼šé•¿æ—¶é—´ä½¿ç”¨åå‡ºç°é›¶ç‚¹æ¼‚ç§»
- **åŠ é€Ÿåº¦è®¡å™ªå£°**ï¼šç¯å¢ƒæŒ¯åŠ¨æˆ–è®¾å¤‡å‘çƒ­å½±å“
- **ç£åŠ›è®¡å¹²æ‰°**ï¼šå‘¨å›´ç£åœºç¯å¢ƒå˜åŒ–
- **é‡‡æ ·é¢‘ç‡ä¸ç¨³å®š**ï¼šç³»ç»Ÿè´Ÿè½½å¯¼è‡´é‡‡æ ·é—´éš”æ³¢åŠ¨

#### B. è®¾å¤‡çŠ¶æ€å˜åŒ–
- **ç”µæ± ç”µé‡**ï¼šç”µé‡ä½æ—¶ä¼ æ„Ÿå™¨æ€§èƒ½ä¸‹é™
- **æ¸©åº¦å½±å“**ï¼šè®¾å¤‡å‘çƒ­å½±å“ä¼ æ„Ÿå™¨ç²¾åº¦
- **å†…å­˜å‹åŠ›**ï¼šç³»ç»Ÿèµ„æºä¸è¶³å½±å“æ•°æ®å¤„ç†
- **åå°è¿›ç¨‹**ï¼šå…¶ä»–åº”ç”¨å ç”¨CPUèµ„æº

### 2. ç®—æ³•å±‚é¢çš„é—®é¢˜

#### A. é˜ˆå€¼è®¾ç½®
```python
# å¯èƒ½å­˜åœ¨çš„é—®é¢˜
TURN_THRESHOLD = 30  # å›ºå®šé˜ˆå€¼å¯èƒ½ä¸é€‚åº”æ‰€æœ‰æƒ…å†µ
MOVEMENT_THRESHOLD = 0.5  # æœªè€ƒè™‘è®¾å¤‡å·®å¼‚

# æ”¹è¿›å»ºè®®
TURN_THRESHOLD_RANGE = (25, 35)  # ä½¿ç”¨èŒƒå›´è€Œéå›ºå®šå€¼
ADAPTIVE_THRESHOLD = True  # å¯ç”¨è‡ªé€‚åº”é˜ˆå€¼
```

#### B. æ»¤æ³¢ç®—æ³•
```python
# å½“å‰å¯èƒ½çš„ç®€å•å¤„ç†
raw_gyro_data = get_sensor_data()
turn_count = count_turns(raw_gyro_data)

# æ”¹è¿›çš„æ»¤æ³¢å¤„ç†
filtered_data = apply_low_pass_filter(raw_gyro_data)
smoothed_data = apply_moving_average(filtered_data, window_size=5)
turn_count = count_turns_with_hysteresis(smoothed_data)
```

#### C. æ—¶é—´çª—å£å¤„ç†
```python
# å¯èƒ½çš„é—®é¢˜ï¼šå›ºå®šæ—¶é—´çª—å£
def analyze_behavior(data, window_size=10):
    # å›ºå®šçª—å£å¯èƒ½é”™è¿‡è¾¹ç•Œæƒ…å†µ
    
# æ”¹è¿›ï¼šé‡å æ—¶é—´çª—å£
def analyze_behavior_improved(data, window_size=10, overlap=0.5):
    # ä½¿ç”¨é‡å çª—å£æé«˜ç¨³å®šæ€§
```

### 3. ç¯å¢ƒå› ç´ 

#### A. æµ‹è¯•ç¯å¢ƒ
- **åœ°é¢æè´¨**ï¼šä¸åŒæè´¨å½±å“æŒ¯åŠ¨ä¼ æ’­
- **å‘¨å›´æ´»åŠ¨**ï¼šå…¶ä»–äººå‘˜æ´»åŠ¨äº§ç”Ÿå¹²æ‰°
- **è®¾å¤‡æ”¾ç½®**ï¼šæ¯æ¬¡æµ‹è¯•çš„è®¾å¤‡æ–¹å‘å¯èƒ½ç•¥æœ‰ä¸åŒ
- **ç½‘ç»œçŠ¶å†µ**ï¼šæ•°æ®ä¼ è¾“å»¶è¿Ÿå½±å“æ—¶é—´æˆ³

#### B. æ“ä½œå·®å¼‚
- **æµ‹è¯•äººå‘˜**ï¼šä¸åŒäººå‘˜çš„æ“ä½œä¹ æƒ¯
- **æµ‹è¯•æ—¶é•¿**ï¼šæµ‹è¯•æŒç»­æ—¶é—´çš„å¾®å°å·®å¼‚
- **å¼€å§‹æ—¶æœº**ï¼šå¯åŠ¨æµ‹è¯•çš„ç²¾ç¡®æ—¶æœº

## ğŸ› ï¸ è§£å†³æ–¹æ¡ˆ

### 1. ç«‹å³å¯å®æ–½çš„æ”¹è¿›

#### A. å¢åŠ æ•°æ®é¢„å¤„ç†
```python
class DataPreprocessor:
    def __init__(self):
        self.calibration_data = {}
        self.noise_profile = {}
    
    def calibrate_sensors(self, static_period_data):
        """ä½¿ç”¨é™æ­¢æœŸé—´æ•°æ®æ ¡å‡†ä¼ æ„Ÿå™¨é›¶ç‚¹"""
        self.gyro_offset = np.mean(static_period_data['gyro'], axis=0)
        self.accel_offset = np.mean(static_period_data['accel'], axis=0)
    
    def apply_noise_filter(self, raw_data):
        """åº”ç”¨å™ªå£°æ»¤æ³¢"""
        # ä½é€šæ»¤æ³¢
        filtered = butter_lowpass_filter(raw_data, cutoff=2.0, fs=50)
        # ç§»åŠ¨å¹³å‡
        smoothed = moving_average(filtered, window=3)
        return smoothed
```

#### B. å®ç°è‡ªé€‚åº”é˜ˆå€¼
```python
class AdaptiveThresholdDetector:
    def __init__(self):
        self.threshold_history = []
        self.adaptation_rate = 0.1
    
    def update_threshold(self, recent_data):
        """æ ¹æ®æœ€è¿‘æ•°æ®åŠ¨æ€è°ƒæ•´é˜ˆå€¼"""
        noise_level = np.std(recent_data)
        signal_strength = np.mean(np.abs(recent_data))
        
        # åŠ¨æ€è®¡ç®—é˜ˆå€¼
        adaptive_threshold = signal_strength * 0.3 + noise_level * 2
        
        # å¹³æ»‘è°ƒæ•´
        if self.threshold_history:
            current = self.threshold_history[-1]
            adaptive_threshold = current * (1-self.adaptation_rate) + adaptive_threshold * self.adaptation_rate
        
        self.threshold_history.append(adaptive_threshold)
        return adaptive_threshold
```

#### C. å¤šé‡éªŒè¯æœºåˆ¶
```python
class BehaviorClassifier:
    def __init__(self):
        self.confidence_threshold = 0.8
        self.vote_count = 3
    
    def classify_with_confidence(self, data_window):
        """ä½¿ç”¨å¤šç§æ–¹æ³•è¿›è¡Œåˆ†ç±»å¹¶è®¡ç®—ç½®ä¿¡åº¦"""
        results = []
        
        # æ–¹æ³•1ï¼šåŸºäºè½¬å‘æ¬¡æ•°
        result1 = self.classify_by_turns(data_window)
        results.append(result1)
        
        # æ–¹æ³•2ï¼šåŸºäºç§»åŠ¨æ¨¡å¼
        result2 = self.classify_by_movement_pattern(data_window)
        results.append(result2)
        
        # æ–¹æ³•3ï¼šåŸºäºé¢‘åŸŸç‰¹å¾
        result3 = self.classify_by_frequency_features(data_window)
        results.append(result3)
        
        # æŠ•ç¥¨å†³å®šæœ€ç»ˆç»“æœ
        final_result = self.majority_vote(results)
        confidence = self.calculate_confidence(results)
        
        return final_result, confidence
```

### 2. ç³»ç»Ÿæ€§æ”¹è¿›æ–¹æ¡ˆ

#### A. æ•°æ®è´¨é‡ç›‘æ§
```python
class DataQualityMonitor:
    def __init__(self):
        self.quality_metrics = {}
    
    def assess_data_quality(self, sensor_data):
        """è¯„ä¼°æ•°æ®è´¨é‡"""
        quality_score = 1.0
        
        # æ£€æŸ¥é‡‡æ ·ç‡ç¨³å®šæ€§
        sampling_rate_variance = self.check_sampling_rate(sensor_data)
        if sampling_rate_variance > 0.1:
            quality_score *= 0.8
        
        # æ£€æŸ¥ä¼ æ„Ÿå™¨å™ªå£°æ°´å¹³
        noise_level = self.check_noise_level(sensor_data)
        if noise_level > self.noise_threshold:
            quality_score *= 0.7
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        data_completeness = self.check_completeness(sensor_data)
        quality_score *= data_completeness
        
        return quality_score
```

#### B. æµ‹è¯•æ ‡å‡†åŒ–
```python
class StandardizedTestProtocol:
    def __init__(self):
        self.test_config = {
            'warm_up_time': 30,  # ä¼ æ„Ÿå™¨é¢„çƒ­æ—¶é—´
            'calibration_time': 10,  # æ ¡å‡†æ—¶é—´
            'test_duration': 300,  # æ ‡å‡†æµ‹è¯•æ—¶é•¿
            'cool_down_time': 10   # å†·å´æ—¶é—´
        }
    
    def run_standardized_test(self):
        """æ‰§è¡Œæ ‡å‡†åŒ–æµ‹è¯•æµç¨‹"""
        # 1. è®¾å¤‡é¢„çƒ­
        self.warm_up_sensors()
        
        # 2. é›¶ç‚¹æ ¡å‡†
        calibration_data = self.collect_calibration_data()
        self.apply_calibration(calibration_data)
        
        # 3. æ­£å¼æµ‹è¯•
        test_data = self.collect_test_data()
        
        # 4. æ•°æ®éªŒè¯
        if self.validate_data_quality(test_data):
            return self.process_results(test_data)
        else:
            return self.retry_test()
```

### 3. éªŒè¯å’Œç›‘æ§

#### A. é‡å¤æ€§éªŒè¯
```python
def repeatability_test():
    """é‡å¤æ€§æµ‹è¯•éªŒè¯"""
    results = []
    
    for i in range(10):  # è¿ç»­10æ¬¡æµ‹è¯•
        result = run_single_test()
        results.append(result)
        
        # ç­‰å¾…é—´éš”ï¼Œé¿å…è¿ç»­æµ‹è¯•å¹²æ‰°
        time.sleep(60)
    
    # åˆ†æç»“æœä¸€è‡´æ€§
    cv = coefficient_of_variation(results)  # å˜å¼‚ç³»æ•°
    if cv < 0.1:  # å˜å¼‚ç³»æ•°å°äº10%
        return "PASS", cv
    else:
        return "FAIL", cv
```

#### B. å®æ—¶ç›‘æ§ä»ªè¡¨æ¿
```python
class TestConsistencyDashboard:
    def __init__(self):
        self.metrics = {
            'turn_count_variance': [],
            'classification_accuracy': [],
            'data_quality_score': []
        }
    
    def update_metrics(self, test_result):
        """æ›´æ–°æµ‹è¯•æŒ‡æ ‡"""
        self.metrics['turn_count_variance'].append(test_result.variance)
        self.metrics['classification_accuracy'].append(test_result.accuracy)
        self.metrics['data_quality_score'].append(test_result.quality)
        
        # æ£€æŸ¥å¼‚å¸¸
        self.check_for_anomalies()
    
    def generate_report(self):
        """ç”Ÿæˆä¸€è‡´æ€§æŠ¥å‘Š"""
        report = {
            'avg_variance': np.mean(self.metrics['turn_count_variance']),
            'trend': self.analyze_trend(),
            'recommendations': self.generate_recommendations()
        }
        return report
```

## ğŸ“ˆ å®æ–½å»ºè®®

### çŸ­æœŸæªæ–½ï¼ˆ1-2å‘¨ï¼‰
1. **ç«‹å³å®æ–½æ•°æ®é¢„å¤„ç†**ï¼šæ·»åŠ æ»¤æ³¢å’Œæ ¡å‡†æ­¥éª¤
2. **æ ‡å‡†åŒ–æµ‹è¯•æµç¨‹**ï¼šç»Ÿä¸€æµ‹è¯•ç¯å¢ƒå’Œæ“ä½œæ­¥éª¤
3. **å¢åŠ é‡å¤æµ‹è¯•**ï¼šæ¯ä¸ªæ¡ä»¶è‡³å°‘æµ‹è¯•3æ¬¡å–å¹³å‡å€¼

### ä¸­æœŸæªæ–½ï¼ˆ1ä¸ªæœˆï¼‰
1. **å®ç°è‡ªé€‚åº”ç®—æ³•**ï¼šæ ¹æ®è®¾å¤‡å’Œç¯å¢ƒåŠ¨æ€è°ƒæ•´å‚æ•°
2. **å»ºç«‹è´¨é‡ç›‘æ§**ï¼šå®æ—¶ç›‘æ§æ•°æ®è´¨é‡å’Œç»“æœä¸€è‡´æ€§
3. **ä¼˜åŒ–é˜ˆå€¼è®¾ç½®**ï¼šåŸºäºå¤§é‡æµ‹è¯•æ•°æ®ä¼˜åŒ–å‚æ•°

### é•¿æœŸæªæ–½ï¼ˆ2-3ä¸ªæœˆï¼‰
1. **æœºå™¨å­¦ä¹ æ–¹æ¡ˆ**ï¼šä½¿ç”¨MLæ¨¡å‹æé«˜åˆ†ç±»å‡†ç¡®æ€§
2. **ä¼ æ„Ÿå™¨èåˆ**ï¼šç»“åˆå¤šç§ä¼ æ„Ÿå™¨æé«˜å¯é æ€§
3. **ç¯å¢ƒæ„ŸçŸ¥**ï¼šè‡ªåŠ¨æ£€æµ‹å’Œé€‚åº”ç¯å¢ƒå˜åŒ–

## ğŸ¯ é¢„æœŸæ•ˆæœ

å®æ–½è¿™äº›æ”¹è¿›åï¼Œé¢„æœŸèƒ½å¤Ÿï¼š
- å°†æµ‹è¯•ç»“æœå˜å¼‚ç³»æ•°é™ä½åˆ°5%ä»¥å†…
- æé«˜è¡Œä¸ºåˆ†ç±»å‡†ç¡®ç‡åˆ°95%ä»¥ä¸Š
- å‡å°‘å› ç¯å¢ƒå˜åŒ–å¯¼è‡´çš„è¯¯åˆ¤
- æä¾›å¯é çš„æ•°æ®è´¨é‡è¯„ä¼°

## ğŸ“‹ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **ç«‹å³åˆ†æ**ï¼šåˆ†æç°æœ‰æµ‹è¯•æ•°æ®ï¼Œæ‰¾å‡ºæœ€å¤§çš„å·®å¼‚æ¥æº
2. **ä¼˜å…ˆå®æ–½**ï¼šå…ˆå®æ–½æ•°æ®é¢„å¤„ç†å’Œæ ‡å‡†åŒ–æµç¨‹
3. **æŒç»­ç›‘æ§**ï¼šå»ºç«‹æµ‹è¯•ç»“æœç›‘æ§æœºåˆ¶
4. **è¿­ä»£æ”¹è¿›**ï¼šæ ¹æ®æ•ˆæœæŒç»­ä¼˜åŒ–ç®—æ³•å‚æ•°
